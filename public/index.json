[
{
	"uri": "//localhost:1313/5-workshop/4-ai/4.1/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " "
},
{
	"uri": "//localhost:1313/5-workshop/5-frontend/5.1/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " "
},
{
	"uri": "//localhost:1313/5-workshop/2-prerequisites/2.1/",
	"title": "Create IAM User &amp; Configure Access Permissions",
	"tags": [],
	"description": "",
	"content": "Create IAM User \u0026amp; Access Setup In this step, you will create an IAM Role for Lambda and an S3 Bucket to store CSV data files before importing them into DynamoDB.\nSteps to Perform 1. Access the IAM Service Go to the AWS Management Console → search for IAM. Select Roles → Create Role. Choose Trusted entity type: AWS service. Choose Use case: Lambda, then click Next. 2. Attach Permissions to the Role Attach the following policies:\nAmazonS3FullAccess AmazonDynamoDBFullAccess_v2 Click Next, then name the role LambdaS3DynamoDBRole.\nThis role allows Lambda to read files from S3 and write data to DynamoDB.\n"
},
{
	"uri": "//localhost:1313/5-workshop/1-introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Introduction "
},
{
	"uri": "//localhost:1313/5-workshop/3-backend/3.1/",
	"title": "Prepare &amp; Configure Lambda Trigger for S3",
	"tags": [],
	"description": "",
	"content": "Prepare \u0026amp; Configure Lambda Trigger for S3 Create an S3 Bucket Go to the S3 service. In the S3 interface, select Create bucket. On the Create bucket screen:\nBucket name: Enter a name, for example:\nflyora-bucket (If the name already exists, add a number at the end.)\nKeep all other default settings unchanged.\nReview your configuration and click Create bucket to finish. Expected Results The flyora-bucket (or your chosen name) is successfully created. The LambdaS3DynamoDBRole role is ready to be assigned to Lambda in the next step. Configure Lambda Trigger for S3 In this step, you will configure AWS Lambda to automatically import CSV files into DynamoDB whenever a new file is uploaded to the S3 Bucket.\nCreate a Lambda Function Go to Lambda → Create function. Select Author from scratch. Function name: AutoImportCSVtoDynamoDB. Runtime: Python 3.13. Role: select LambdaS3DynamoDBRole created in the previous step. Add a Trigger In the Configuration → Triggers tab, click Add trigger. Choose S3. Select Bucket flyora-bucket. Event type: All object create events. Click Add to save. Paste the Lambda Code\nPaste the following code: import boto3 import csv import io import json from botocore.exceptions import ClientError dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) s3 = boto3.client(\u0026#39;s3\u0026#39;) def create_table_if_not_exists(table_name, sample_item): existing_tables = dynamodb.meta.client.list_tables()[\u0026#39;TableNames\u0026#39;] if table_name in existing_tables: print(f\u0026#34;Table \u0026#39;{table_name}\u0026#39; already exists.\u0026#34;) return # Use the first key as the Partition key partition_key = list(sample_item.keys())[0] print(f\u0026#34;Creating new table: {table_name} with partition key: {partition_key}\u0026#34;) table = dynamodb.create_table( TableName=table_name, KeySchema=[{\u0026#39;AttributeName\u0026#39;: partition_key, \u0026#39;KeyType\u0026#39;: \u0026#39;HASH\u0026#39;}], AttributeDefinitions=[{\u0026#39;AttributeName\u0026#39;: partition_key, \u0026#39;AttributeType\u0026#39;: \u0026#39;S\u0026#39;}], BillingMode=\u0026#39;PAY_PER_REQUEST\u0026#39; ) table.wait_until_exists() print(f\u0026#34;Table \u0026#39;{table_name}\u0026#39; created successfully.\u0026#34;) def lambda_handler(event, context): try: for record in event[\u0026#39;Records\u0026#39;]: bucket = record[\u0026#39;s3\u0026#39;][\u0026#39;bucket\u0026#39;][\u0026#39;name\u0026#39;] key = record[\u0026#39;s3\u0026#39;][\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;] print(f\u0026#34;Processing file: {key} from bucket: {bucket}\u0026#34;) response = s3.get_object(Bucket=bucket, Key=key) body = response[\u0026#39;Body\u0026#39;].read().decode(\u0026#39;utf-8\u0026#39;) reader = csv.DictReader(io.StringIO(body)) items = list(reader) if not items: print(f\u0026#34;File {key} is empty, skipping.\u0026#34;) continue table_name = key.split(\u0026#39;.\u0026#39;)[0] # table name = file name (without .csv) create_table_if_not_exists(table_name, items[0]) table = dynamodb.Table(table_name) with table.batch_writer() as batch: for item in items: batch.put_item(Item=item) print(f\u0026#34;Imported {len(items)} records into {table_name}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;Import completed successfully\u0026#39;) } except ClientError as e: print(f\u0026#34;AWS Error: {e.response[\u0026#39;Error\u0026#39;][\u0026#39;Message\u0026#39;]}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 500, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;AWS Error\u0026#39;)} except Exception as e: print(f\u0026#34;General Error: {str(e)}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 500, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;General Error\u0026#39;)} Click Deploy and confirm it shows Successfully. "
},
{
	"uri": "//localhost:1313/5-workshop/4-ai/4.2/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " "
},
{
	"uri": "//localhost:1313/5-workshop/5-frontend/5.2/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " "
},
{
	"uri": "//localhost:1313/5-workshop/2-prerequisites/",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": "Environment Setup "
},
{
	"uri": "//localhost:1313/5-workshop/2-prerequisites/2.2/",
	"title": "Something we will figure out later :))",
	"tags": [],
	"description": "",
	"content": "Something we will figure out later :)) "
},
{
	"uri": "//localhost:1313/5-workshop/3-backend/3.2/",
	"title": "Verify Data in DynamoDB",
	"tags": [],
	"description": "",
	"content": "Verify Data in DynamoDB In this step, you will verify that the data from the CSV file has been successfully imported into DynamoDB.\nSteps to Perform Upload the CSV File to the Bucket Download the sample CSV file from here.\nIn the newly created Bucket:\nGo to the Objects tab → click Upload. Drag and drop the file products.csv, then click Upload. [!TIP] After uploading, please wait about 3–5 minutes for the Lambda function to import the data.\nAccess the DynamoDB Service Go to AWS Management Console → search for DynamoDB. Select Tables → click on the products table. View the Data Open the Explore items tab. Check the list of products that have been imported. If you don\u0026rsquo;t see any data, please check the following:\nThe DynamoDB table name must match the CSV file name. The CSV file must have a valid header. The Lambda function must have sufficient permissions to access both S3 and DynamoDB. "
},
{
	"uri": "//localhost:1313/5-workshop/4-ai/4.3/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " "
},
{
	"uri": "//localhost:1313/5-workshop/5-frontend/5.3/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " "
},
{
	"uri": "//localhost:1313/5-workshop/3-backend/",
	"title": "Backend Workshop (API &amp; Data Layer)",
	"tags": [],
	"description": "",
	"content": "Backend: API \u0026amp; Data Pipeline In this workshop, you will:\nUse Amazon S3 to store input data (CSV files). Configure AWS Lambda Trigger to automatically import data into DynamoDB. Create Lambda (API Handler) and expose it through API Gateway to access DynamoDB data. Test REST API endpoints via Postman or API Gateway Console. Clean up all resources after completion. "
},
{
	"uri": "//localhost:1313/5-workshop/3-backend/3.3/",
	"title": "Create API Gateway &amp; Integrate with Lambda",
	"tags": [],
	"description": "",
	"content": "Objective Create a new Lambda Function to handle requests to DynamoDB via API Gateway..\nSteps to Follow Step 1: Create IAM Role Open IAM Console → Roles → Create role Select Trusted entity: AWS Service → Lambda Attach permissions: AmazonDynamoDBFullAccess CloudWatchLogsFullAccess Name the role: LambdaAPIAccessRole Step 2: Create Lambda Function Go to AWS Lambda → Create function Select Author from scratch Name: DynamoDB_API_Handler Runtime: Python 3.13 Select IAM Role: LambdaAPIAccessRole Bước 3: Paste Example Code ```python\rimport boto3\rimport json\rfrom decimal import Decimal\rdynamodb = boto3.resource('dynamodb')\rclass DecimalEncoder(json.JSONEncoder):\rdef default(self, obj):\rif isinstance(obj, Decimal):\rreturn int(obj) if obj % 1 == 0 else float(obj)\rreturn super(DecimalEncoder, self).default(obj)\rdef lambda_handler(event, context):\rtry:\rmethod = event.get('httpMethod', 'GET')\rpath = event.get('path', '') body = json.loads(event.get('body', '{}')) if event.get('body') else {}\rpath_to_table = {\r'/api/account': 'Account',\r'/api/admin': 'Admin',\r'/api/role': 'Role',\r'/api/customer': 'Customer',\r'/api/staff': 'SalesStaff',\r'/api/owner': 'ShopOwner',\r'/api/product': 'Product',\r'/api/category': 'ProductCategory',\r'/api/review': 'ProductReview',\r'/api/promotion': 'Promotion',\r'/api/inventory': 'Inventory',\r'/api/type/food': 'FoodType',\r'/api/type/furniture': 'FurnitureType',\r'/api/type/toy': 'ToyType',\r'/api/type/bird': 'BirdType',\r'/api/detail/food': 'FoodDetail',\r'/api/detail/furniture': 'FurnitureDetail',\r'/api/detail/toy': 'ToyDetail',\r'/api/order': 'Order',\r'/api/order-item': 'OrderItem',\r'/api/payment': 'Payment',\r'/api/payment-method': 'PaymentMethod',\r'/api/delivery-note': 'DeliveryNote',\r'/api/shipping-method': 'ShippingMethod',\r'/api/notification': 'Notification',\r'/api/notification-type': 'NotificationType',\r'/api/chatbot': 'ChatBot',\r'/api/faq': 'FAQ',\r'/api/new': 'NewsArticle',\r'/api/log/access': 'AccessLog',\r'/api/log/system': 'SystemLog',\r'/api/issue': 'IssueReport',\r'/api/policy': 'Policy'\r}\rtable_name = path_to_table.get(path)\rif not table_name:\rreturn {\r'statusCode': 404,\r'body': json.dumps({'error': f'Unknown API path: {path}'})\r}\rtable = dynamodb.Table(table_name)\rif method == 'GET':\rresponse = table.scan()\rreturn {\r'statusCode': 200,\r'headers': {'Content-Type': 'application/json'},\r'body': json.dumps(response['Items'], cls=DecimalEncoder)\r}\relif method == 'POST':\ritem = body.get('item')\rif not item:\rreturn {\r'statusCode': 400,\r'body': json.dumps({'error': 'Missing item data'})\r}\rtable.put_item(Item=item)\rreturn {\r'statusCode': 200,\r'headers': {'Content-Type': 'application/json'},\r'body': json.dumps({'message': 'Item added successfully', 'item': item}, cls=DecimalEncoder)\r}\relif method == 'PUT':\ritem = body.get('item')\rif not item:\rreturn {\r'statusCode': 400,\r'body': json.dumps({'error': 'Missing item data for update'})\r}\rtable.put_item(Item=item)\rreturn {\r'statusCode': 200,\r'headers': {'Content-Type': 'application/json'},\r'body': json.dumps({'message': 'Item updated successfully', 'item': item}, cls=DecimalEncoder)\r}\relif method == 'DELETE':\rkey = body.get('key')\rif not key:\rreturn {\r'statusCode': 400,\r'body': json.dumps({'error': 'Missing key for delete'})\r}\rtable.delete_item(Key=key)\rreturn {\r'statusCode': 200,\r'body': json.dumps({'message': 'Item deleted successfully'})\r}\relse:\rreturn {\r'statusCode': 405,\r'body': json.dumps({'error': f'Method {method} not allowed'})\r}\rexcept Exception as e:\rreturn {\r'statusCode': 500,\r'body': json.dumps({'error': str(e)})\r}\r"
},
{
	"uri": "//localhost:1313/5-workshop/4-ai/",
	"title": "AI Workshop (Chatbot)",
	"tags": [],
	"description": "",
	"content": "AI Chatbot Development "
},
{
	"uri": "//localhost:1313/5-workshop/3-backend/3.4/",
	"title": "Test API using Postman",
	"tags": [],
	"description": "",
	"content": "API Testing "
},
{
	"uri": "//localhost:1313/5-workshop/5-frontend/",
	"title": "Frontend Workshop (UI)",
	"tags": [],
	"description": "",
	"content": "Frontend Development \u0026amp; Chatbot Embedding "
},
{
	"uri": "//localhost:1313/5-workshop/3-backend/3.5/",
	"title": "Test API using Postman",
	"tags": [],
	"description": "",
	"content": "API Testing "
},
{
	"uri": "//localhost:1313/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Deploying the Flyora E-commerce System on AWS Overview In this workshop, you will deploy the core components of the Flyora platform using a Serverless architecture on AWS.\nThe objective is to build a system that is scalable, cost-efficient, and easy to maintain.\nComponents to be deployed:\nFrontend: Store \u0026amp; deliver UI via S3 + CloudFront Backend API: Handle business logic with API Gateway + AWS Lambda Database: Manage product / order data using DynamoDB + S3 User Authentication: Implemented via Amazon Cognito Chatbot: Product consultation assistant integrated into UI (handled by AI Team) The workshop is divided into group roles for parallel development: Backend (BE), AI (Chatbot), and Frontend (FE).\nSystem Architecture Workshop Content Introduction: Objectives \u0026amp; Expected Outcomes\nEnvironment Setup (Prerequisites)\nCreate IAM User + Configure Access Permissions Something we will figure out later :)) Backend Workshop (BE) — Build API + Automated Data Import Pipeline\nPrepare \u0026amp; upload CSV data to S3 Create Lambda to automatically write CSV data to DynamoDB (S3 Trigger) Create API Gateway and integrate Lambda as Backend API Test API via Postman / API Gateway Console AI Workshop (Chatbot) — Product Consultation Support\n(AI team will fill in content) (AI team will fill in content) (AI team will fill in content) Frontend Workshop (FE) — Display Data \u0026amp; Integrate Chatbot\n(Frontend team will fill in content) (Frontend team will fill in content) (Frontend team will fill in content) Set Up CI/CD for Automatic Deployment\nSystem Testing \u0026amp; Performance Evaluation\nResource Cleanup to Avoid Unnecessary Charges\nThis workshop is designed to run within the AWS Free Tier,\nusing no EC2, no SSH, and no paid services beyond free tier limits.\n"
},
{
	"uri": "//localhost:1313/5-workshop/6-cicd/",
	"title": "CI/CD Automation (Optional Step)",
	"tags": [],
	"description": "",
	"content": "CI/CD Pipeline Setup "
},
{
	"uri": "//localhost:1313/5-workshop/7-testing/",
	"title": "System Testing &amp; Performance Review",
	"tags": [],
	"description": "",
	"content": "System Testing "
},
{
	"uri": "//localhost:1313/5-workshop/8-cleanup/",
	"title": "Clean Up Resources to Avoid AWS Charges",
	"tags": [],
	"description": "",
	"content": "Clean Up AWS Resources "
},
{
	"uri": "//localhost:1313/",
	"title": "AWS System Manager",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]